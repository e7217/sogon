# ====================================
# API Configuration
# ====================================

# Groq API (for fast Whisper transcription)
GROQ_API_KEY="your-groq-api-key"

# Legacy OpenAI API (for backward compatibility)
OPENAI_API_KEY="your-openai-api-key"
OPENAI_BASE_URL="https://api.openai.com/v1"
OPENAI_MODEL="gpt-4o-mini"
OPENAI_TEMPERATURE=0.3
OPENAI_MAX_CONCURRENT_REQUESTS=10
OPENAI_MAX_TOKENS=4000

# ====================================
# Transcription Service Configuration
# ====================================

# Provider: groq (recommended) or openai
TRANSCRIPTION_PROVIDER="groq"

# API key for transcription (optional, falls back to GROQ_API_KEY or OPENAI_API_KEY)
# TRANSCRIPTION_API_KEY="your-transcription-specific-api-key"

# Base URL for transcription service
TRANSCRIPTION_BASE_URL="https://api.groq.com/openai/v1"

# Whisper model to use
TRANSCRIPTION_MODEL="whisper-large-v3-turbo"

# Temperature for transcription (0.0 for consistent results)
TRANSCRIPTION_TEMPERATURE=0.0

# Response format for transcription
TRANSCRIPTION_RESPONSE_FORMAT="verbose_json"

# ====================================
# Translation Service Configuration
# ====================================

# Provider: openai (default), azure, or anthropic
TRANSLATION_PROVIDER="openai"

# API key for translation (optional, falls back to OPENAI_API_KEY)
# TRANSLATION_API_KEY="your-translation-specific-api-key"

# Base URL for translation service
TRANSLATION_BASE_URL="https://api.openai.com/v1"

# Model for translation
TRANSLATION_MODEL="gpt-4o-mini"

# Temperature for translation
TRANSLATION_TEMPERATURE=0.3

# Max tokens for translation
TRANSLATION_MAX_TOKENS=4000

# ====================================
# Correction Service Configuration
# ====================================

# Provider: openai (default), azure, or anthropic
CORRECTION_PROVIDER="openai"

# API key for correction (optional, falls back to OPENAI_API_KEY)
# CORRECTION_API_KEY="your-correction-specific-api-key"

# Base URL for correction service
CORRECTION_BASE_URL="https://api.openai.com/v1"

# Model for text correction
CORRECTION_MODEL="gpt-4o-mini"

# Temperature for correction (lower for more conservative corrections)
CORRECTION_TEMPERATURE=0.1

# Max tokens for correction
CORRECTION_MAX_TOKENS=4000

# Enable correction by default (set to true to always apply correction)
ENABLE_CORRECTION_BY_DEFAULT=false

# ====================================
# Audio Processing Configuration
# ====================================

# Maximum chunk size for audio processing (in MB)
MAX_CHUNK_SIZE_MB=24

# Timeout for chunk processing (in seconds)
CHUNK_TIMEOUT_SECONDS=120

# Supported audio formats (comma-separated)
AUDIO_FORMATS="mp3,m4a,wav"

# Supported video formats (comma-separated)
VIDEO_FORMATS="mp4,avi,mov,wmv,flv,mkv,webm"

# Audio quality for downloads
AUDIO_QUALITY="128k"

# Audio format settings for transcription optimization
AUDIO_SAMPLE_RATE=16000  # 16kHz for Whisper optimization
AUDIO_CHANNELS=1         # Mono (1) or Stereo (2)

# ====================================
# YouTube Download Configuration
# ====================================

# Socket timeout for YouTube downloads (in seconds)
YOUTUBE_SOCKET_TIMEOUT=30

# Number of retries for failed downloads
YOUTUBE_RETRIES=3

# Preferred audio format for YouTube downloads
YOUTUBE_PREFERRED_FORMAT="m4a"

# Enable translation by default
ENABLE_TRANSLATION_BY_DEFAULT=false

# Default target language for translation
DEFAULT_TRANSLATION_LANGUAGE="ko"

# ====================================
# File Management Configuration
# ====================================

# Keep temporary files after processing
KEEP_TEMP_FILES=false

# Base directory for output files
OUTPUT_BASE_DIR="./result"

# ====================================
# Logging Configuration
# ====================================

# Log level (DEBUG, INFO, WARNING, ERROR, CRITICAL)
LOG_LEVEL="INFO"

# Log file name
LOG_FILE="sogon.log"

# Maximum log file size (in bytes)
LOG_MAX_BYTES=10485760

# Number of backup log files to keep
LOG_BACKUP_COUNT=5

# ====================================
# Performance Configuration
# ====================================

# Maximum number of worker threads
MAX_WORKERS=4

# Maximum processing timeout (in seconds)
MAX_PROCESSING_TIMEOUT_SECONDS=1800
